layers
======

.. only:: html

  Classes
  -------

  `class Add <layers/Add.html>`_
  : The layer to add a sequence of inputs.

  `class AveragePooling2D <layers/AveragePooling2D.html>`_
  : The average 2d pooling layer.

  `class BatchNormalization <layers/BatchNormalization.html>`_
  : The batch normalization layer.
  `[Ioffe & Szegedy, 2015] <https://arxiv.org/abs/1502.03167>`_.

  `class Concatenate <layers/Concatenate.html>`_
  : The layer to concatenate a sequence of inputs.

  `class Conv2D <layers/Conv2D.html>`_
  : The 2d convolution layer.

  `class Conv2DTranspose <layers/Conv2DTranspose.html>`_
  : The 2d deconvolution layer.

  `class Dense <layers/Dense.html>`_
  : The fully-connected layer.

  `class DepthwiseConv2D <layers/DepthwiseConv2D.html>`_
  : The 2d depthwise convolution layer.
  `[Chollet, 2016] <https://arxiv.org/abs/1610.02357>`_.

  `class Dropout <layers/Dropout.html>`_
  : The dropout layer.
  `[Srivastava et.al, 2014] <http://jmlr.org/papers/v15/srivastava14a.html>`_.

  `class ELU <layers/ELU.html>`_
  : The layer to apply the exponential linear unit.
  `[Clevert et.al, 2015] <https://arxiv.org/abs/1511.07289>`_.

  `class Flatten <layers/Flatten.html>`_
  : The layer to reshape input into a matrix.

  `class GlobalAveragePooling2D <layers/GlobalAveragePooling2D.html>`_
  : The global average 2d pooling layer.

  `class GlobalMaxPool2D <layers/GlobalMaxPool2D.html>`_
  : The global max 2d pooling layer.

  `class Layer <layers/Layer.html>`_
  : The base class of layers.

  `class LeakyReLU <layers/LeakyReLU.html>`_
  : The layer to apply the leaky rectified linear unit.

  `class Maximum <layers/Maximum.html>`_
  : The layer to compute the maximum of a sequence of inputs.

  `class MaxPool2D <layers/MaxPool2D.html>`_
  : The max 2d pooling layer.

  `class Minimum <layers/Minimum.html>`_
  : The layer to compute the minimum of a sequence of inputs.

  `class Multiply <layers/Multiply.html>`_
  : The layer to multiply a sequence of inputs.

  `class Permute <layers/Permute.html>`_
  : The layer to permute the dimensions of input.

  `class Reshape <layers/Reshape.html>`_
  : The layer to change the dimensions of input.

  `class ReLU <layers/ReLU.html>`_
  : The layer to apply the rectified linear unit.
  `[Nair & Hinton, 2010] <http://www.csri.utoronto.ca/~hinton/absps/reluICML.pdf>`_.

  `class SELU <layers/SELU.html>`_
  : Apply the scaled exponential linear unit.
  `[Klambauer et.al, 2017] <https://arxiv.org/abs/1706.02515>`_.

  `class Softmax <layers/Softmax.html>`_
  : The layer to apply the softmax function.

  `class Subtract <layers/Subtract.html>`_
  : The layer to subtract two inputs.

.. toctree::
  :hidden:

  layers/Add
  layers/AveragePooling2D
  layers/BatchNormalization
  layers/Concatenate
  layers/Conv2D
  layers/Conv2DTranspose
  layers/Dense
  layers/DepthwiseConv2D
  layers/Dropout
  layers/ELU
  layers/Flatten
  layers/GlobalAveragePooling2D
  layers/GlobalMaxPool2D
  layers/Layer
  layers/LeakyReLU
  layers/Maximum
  layers/MaxPool2D
  layers/Minimum
  layers/Multiply
  layers/Permute
  layers/ReLU
  layers/Reshape
  layers/SELU
  layers/Softmax
  layers/Subtract

.. raw:: html

  <style>
  h1:before {
    content: "Module: tf.keras.";
    color: #103d3e;
  }
  </style>
